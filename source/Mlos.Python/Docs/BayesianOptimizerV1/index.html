<!DOCTYPE html>
<html lang="en" dir=>

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Bayesian Optimizer V1 The goal of this document is to describe the architecture and inner workings of a Bayesian Optimizer.
Components The following components will be necessary:
 Experiment Observation Storage (Table in SQL Server) Bayesian Optimizer Surrogate Models  Architecture TODO: describe how we will use the technologies:
 Docker (K8S?) SQL Server Python ML.Net SQL DB RPC vs. gRPC  Obviously an experiment and the corresponding bayesian optimizer have to be compatible so that the observations generated by the experiment are within the optimizers observation space.">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="" />
<meta property="og:description" content="Bayesian Optimizer V1 The goal of this document is to describe the architecture and inner workings of a Bayesian Optimizer.
Components The following components will be necessary:
 Experiment Observation Storage (Table in SQL Server) Bayesian Optimizer Surrogate Models  Architecture TODO: describe how we will use the technologies:
 Docker (K8S?) SQL Server Python ML.Net SQL DB RPC vs. gRPC  Obviously an experiment and the corresponding bayesian optimizer have to be compatible so that the observations generated by the experiment are within the optimizers observation space." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://microsoft.github.io/MLOS/source/Mlos.Python/Docs/BayesianOptimizerV1/" />

<title>Bayesian Optimizer V1 | MLOS</title>
<link rel="manifest" href="/MLOS/manifest.json">
<link rel="icon" href="/MLOS/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/MLOS/book.min.6cd8553a6854f4812343f0f0c8baca31271e686434f381fbe3c7226f66639176.css" integrity="sha256-bNhVOmhU9IEjQ/DwyLrKMSceaGQ084H748cib2ZjkXY=">
<script defer src="/MLOS/en.search.min.a8b562ed762012adb05ca46b05f05c9636762e9f903d1ff2c9acccdb0928e46f.js" integrity="sha256-qLVi7XYgEq2wXKRrBfBcljZ2Lp&#43;QPR/yyazM2wko5G8="></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body dir=>
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      
  <nav>
<h2 class="book-brand">
  <a href="/MLOS"><span>MLOS</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>











  <ul>
<li>
<p><a href="/MLOS/documentation/">Documentation</a></p>
<ul>
<li><a href="/MLOS/documentation/01-Prerequisites/">Prerequisites</a></li>
<li><a href="/MLOS/documentation/02-Build/">Build</a></li>
<li><a href="/MLOS/documentation/04-Test/">Test</a></li>
<li><a href="/MLOS/documentation/CodingStandard/">Coding Standard</a></li>
<li><a href="/MLOS/documentation/MlosArchitecture/">Architecture</a></li>
<li><a href="/MLOS/documentation/RepoOrganization/">Repo Organization</a></li>
</ul>
</li>
<li>
<p><a href="/MLOS/notebooks/">Notebooks</a></p>
<ul>
<li><a href="/MLOS/notebooks/BayesianOptimization/">Bayesian Optimization</a></li>
<li><a href="/MLOS/notebooks/SmartCacheOptimization/">Smart Cache Optimization</a></li>
<li><a href="/MLOS/notebooks/SmartCacheCPP/">Smart Cache Optimization in C++</a></li>
<li><a href="/MLOS/notebooks/LevelDbTuning/">LevelDB External Tuning Example</a></li>
</ul>
</li>
<li>
<p><a href="/MLOS/source/Examples/">E2E Examples</a></p>
<ul>
<li><a href="/MLOS/source/Examples/SmartCache/">Smart Cache</a></li>
</ul>
</li>
<li>
<p>API Documentation</p>
<ul>
<li><a href="/MLOS/python_api/">Python</a></li>
</ul>
</li>
<li>
<p>Component Documentation</p>
<ul>
<li><a href="/MLOS/source/Mlos.SettingsSystem.CodeGen/">Mlos Settings System Code Generation System</a></li>
<li><a href="/MLOS/source/Mlos.Core/doc/">Mlos.Core Shared Memory Communication Channel</a></li>
<li><a href="/MLOS/source/Mlos.Agent.Server/">Mlos.Agent.Server</a></li>
</ul>
</li>
<li>
<p><a href="/MLOS/external/">External Integration</a></p>
</li>
<li>
<p><a href="/MLOS/CODE_OF_CONDUCT/">Code of Conduct</a></p>
</li>
<li>
<p><a href="/MLOS/CONTRIBUTING/">Contributing</a></p>
</li>
<li>
<p><a href="https://github.com/Microsoft/MLOS">MLOS Github Repository</a></p>
</li>
</ul>










</nav>




  <script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script>


 
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/MLOS/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Bayesian Optimizer V1</strong>

  <label for="toc-control">
    
    <img src="/MLOS/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  <nav id="TableOfContents">
  <ul>
    <li><a href="#active-vs-online-learning">Active vs. Online Learning</a>
      <ul>
        <li><a href="#active-learning">Active Learning</a></li>
        <li><a href="#online-learning">Online Learning</a></li>
      </ul>
    </li>
    <li><a href="#explore-vs-exploit">Explore vs. Exploit</a>
      <ul>
        <li><a href="#explore">Explore</a></li>
        <li><a href="#exploit">Exploit</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#anatomy-of-a-bayesian-optimizer">Anatomy of a Bayesian Optimizer</a>
      <ul>
        <li><a href="#simple-optimization-flow">Simple optimization flow</a></li>
        <li><a href="#the-role-of-the-surrogate-model">The Role of the Surrogate Model</a></li>
        <li><a href="#the-role-of-the-acquisition-function">The Role of the Acquisition Function</a></li>
        <li><a href="#maximizing-acquisition-function">Maximizing Acquisition Function</a></li>
      </ul>
    </li>
  </ul>
</nav>


  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="bayesian-optimizer-v1">Bayesian Optimizer V1</h1>
<p>The goal of this document is to describe the architecture and inner workings of a Bayesian Optimizer.</p>
<h1 id="components">Components</h1>
<p>The following components will be necessary:</p>
<ol>
<li>Experiment</li>
<li>Observation Storage (Table in SQL Server)</li>
<li>Bayesian Optimizer</li>
<li>Surrogate Models</li>
</ol>
<h1 id="architecture">Architecture</h1>
<p>TODO: describe how we will use the technologies:</p>
<ul>
<li>Docker (K8S?)</li>
<li>SQL Server</li>
<li>Python</li>
<li>ML.Net</li>
<li>SQL DB RPC vs. gRPC</li>
</ul>
<!-- raw HTML omitted -->
<p>Obviously an experiment and the corresponding bayesian optimizer have to be compatible so that the observations generated by the experiment are within the optimizers observation space. Thus the Experiment and the Optimizer should be configured together. One way to accomplish this is to have the <strong>Experiment own an Optimizer</strong>.</p>
<p>An experiment has to further interact with the target. There are two general approaches:</p>
<ol>
<li>Active Learning</li>
<li>Online Learning</li>
</ol>
<h2 id="active-vs-online-learning">Active vs. Online Learning</h2>
<h3 id="active-learning">Active Learning</h3>
<p>In this mode the experiment controls the deployment and the workload. In other words, the experiment can restart the target with a desired configuration, in a desired context, with a desired workload.</p>
<p><strong>A mental shortcut</strong>: we would use this mode in the lab to train models.</p>
<h3 id="online-learning">Online Learning</h3>
<p>In this mode the experiment can observe the target (its deployment context, and performance metrics) but is only allowed to change the configuration.</p>
<p><strong>A mental shortcut</strong>: we would use this mode in production.</p>
<h2 id="explore-vs-exploit">Explore vs. Exploit</h2>
<p>While we are talking about training modes, another dichotomy should be made clear.</p>
<p>We would run the optimizer in an <strong>Explore</strong> mode in the lab or on a &lsquo;B&rsquo; instance of an A/B testing setup. We would only ever run the optimizer in the <strong>Exploit</strong> mode on production deployments, but that&rsquo;s the song of distant future.</p>
<p>The mechanism for controlling the behavior would be to adjust the acquisition function.</p>
<h3 id="explore">Explore</h3>
<p>In Explore mode the optimizer&rsquo;s objective is to explore the search space with the goal of sampling a variety of configurations and building robust surrogate models. This comes at a risk of drastically regressing performance or even crashing the server, but we are OK with that in the lab setting. The payoff is that the optimizer builds models that more completely understand the <em>feasibility region</em> as well as the performance of the target under various configurations.</p>
<h3 id="exploit">Exploit</h3>
<p>In Exploit mode the optimizer&rsquo;s objective is to <strong>conservatively</strong> adjust target&rsquo;s configuration to maximize performance in a given workload. What this means is that the optimizer would only issue a reconfiguration recommendation if it has a very low probability of deteriorating performance.</p>
<!-- raw HTML omitted -->
<h1 id="storage">Storage</h1>
<p>Observations obtained from the target should be passed to the optimizer, but additionally should be stored so that we could experiment with a variety of models. For now, we will use SQL Server as storage for observations, though we could extend it to any other technology as long as required connectors are available / can be written.</p>
<!-- raw HTML omitted -->
<h1 id="bayesian-optimizer">Bayesian Optimizer</h1>
<h2 id="anatomy-of-a-bayesian-optimizer">Anatomy of a Bayesian Optimizer</h2>
<p>A Bayesian Optimizer (BO) consists of two parts, both of which can be interchanged to achieve a variety of goals. Thes are:</p>
<ul>
<li>An acquisition function</li>
<li>A surrogate model or surrogate models ensemble</li>
</ul>
<h3 id="simple-optimization-flow">Simple optimization flow</h3>
<p>Below is a sequence diagram depicting a simple bayesian optimization process.</p>
<pre><code class="language-mermaid" data-lang="mermaid">sequenceDiagram

participant User
participant OptimizationTarget
participant Optimizer
participant SurrogateModel
participant AcquisitionFunction

User -&gt;&gt; OptimizationTarget: Start(defaultConfig)
activate OptimizationTarget

loop while optimizationBudget &gt; 0
    OptimizationTarget -&gt;&gt; Optimizer: observations
    Note over Optimizer, SurrogateModel: regression model is fit to data
    Optimizer -&gt;&gt; SurrogateModel: fit(observations) 

    User -&gt;&gt; Optimizer: SuggestNewConfig()
    Optimizer -&gt;&gt; Optimizer: CandidateConfigs = SearchSpace.Meshgrid()

    loop for config in CandidateConfigs
        Optimizer -&gt;&gt; SurrogateModel: mean, stdev = predict(config)
        Optimizer -&gt;&gt; AcquisitionFunction: score = AcquisitionFunction(mean, stdev)
        Note over Optimizer, AcquisitionFunction: if score &gt; maxScore: maxScore = score, bestConfig = config
    end

    Optimizer -&gt;&gt; User: bestConfig
    User -&gt;&gt; OptimizationTarget: reconfigure(bestConfig)
end

User -&gt;&gt; OptimizationTarget: Stop()
deactivate OptimizationTarget
</code></pre><p>While this process is quite naive, it allows us to discuss the way that a Bayesian Optimizer works.</p>
<ol>
<li>The user starts the OptimizationTarget which emits telemetry. Automagically (in a way irrelevant to our discussion) that telemetry is converted to observations and passed to the optimizer. The optimizer uses all observations to fit a surrogate model (let&rsquo;s assume it&rsquo;s a Gaussian Process).</li>
<li>Eventually, the user is ready to try a new configuration and so the user asks the optimizer for a new config to try.</li>
<li>The optimizer generates a meshgrid of possible configurations.</li>
<li>The model is asked to predict performance and uncertainty for each of the points in the grid.</li>
<li>Those predictions are passed through an acquisition function which returns some score. That function could be: probability of improvement, expected improvement, lower confidence bound, or even an inverse of the probability of catastrophic deterioration. This choice depends on our objective and our constraints. More on that later.</li>
<li>The optimizer selects the configuration with the highest score and returns to the user.</li>
<li>The user reconfigures the target and the story repeats until we run out of budget.</li>
</ol>
<h3 id="the-role-of-the-surrogate-model">The Role of the Surrogate Model</h3>
<p>That role is very simple: predict performance based on configuration. Ideally, a surrogate model should report it&rsquo;s level of uncertainty in the prediction.</p>
<p>TODO: feasibility predictors</p>
<h3 id="the-role-of-the-acquisition-function">The Role of the Acquisition Function</h3>
<p>The role of the acquisition function is difficult to overstate. It is this function that <strong>determines whether the optimizer is in an Explore vs. Exploit mode</strong>. An acquisition function can score each candidate configuration in a number of ways: it can favor configurations close to existing observations so that the risk is minimized. It can favor <em>promising and uncertain</em> configurations to favor exploration.</p>
<p>Some of the popular choices:</p>
<ul>
<li>Probability of Improvement (POI) - maximizes the chance that a new point will be better than the observations we have seen so far.</li>
<li>Expected Improvement (EI) - will select points maximize expected improvement. It much less conservative than POI. POI would select points with high chance of improvement, even if the improvement is infinitesimal. EI will select points so that the improvement is as large as possible.</li>
<li>Lower Confidence Bound - will select poinst with <strong>the highest lower confidence bound</strong>. In a way it is a strategy that is motivated by avoiding risk rather than winning big.</li>
<li>Safe Optimization - this function will attempt to minimize the probability of suggesting a catastrophic configuration. In other words: maximize the probability of safety.</li>
</ul>
<p>Each of the above functions can be further parameterized to tune it to our needs. It is a very rich selection and should be addressed by hyper-parameter tuning and AutoML initiatives.</p>
<h3 id="maximizing-acquisition-function">Maximizing Acquisition Function</h3>
<p>In our naive example above, we used grid search maximize the value of hte Acquisition Function. That is obviously wasteful especially when we realize that we will repeat this step over and over again, for every new suggestion (iteration of the outer loop). Several observations can prove useful:</p>
<ol>
<li>The surrogate model changes only slightly between iterations and those changes are most pronounced in the vicinity of the new observation.</li>
<li>It stands to reason that between iterations points that had a high acquisition function value are likely to stay promising, and points that had a low acquisition value function are likely to remain unpromising. With the exception of points in the vicinity of any new observations.</li>
</ol>
<p>We could use that insight to jump-start our optimization by first considering points that have been promising in the past.</p>
<p>Furthermore, some surrogate model classes can encode clues to their maxima. For example: in a Gaussian Process maxima are likely to occur in the vicinity of the kernels.</p>
<p>Moreover, a plethora of optimization algorithms have been developed over the centuries that should perform better than grid search (especially for smooth functions such as Neural Networks and Gaussian Processes sometimes are). There are direct methods, gradient based methods (first and second order), population methods and even surrogate methods (&hellip; though that last suggestion is bound to raise eye-brows - but that alone should not disqualify it :)).</p>
<p>The point is, by using some of those methods, we are likely to converge on optima faster and save a lot of compute on model scoring.</p>
<!-- raw HTML omitted -->
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>

 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      
  <nav id="TableOfContents">
  <ul>
    <li><a href="#active-vs-online-learning">Active vs. Online Learning</a>
      <ul>
        <li><a href="#active-learning">Active Learning</a></li>
        <li><a href="#online-learning">Online Learning</a></li>
      </ul>
    </li>
    <li><a href="#explore-vs-exploit">Explore vs. Exploit</a>
      <ul>
        <li><a href="#explore">Explore</a></li>
        <li><a href="#exploit">Exploit</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#anatomy-of-a-bayesian-optimizer">Anatomy of a Bayesian Optimizer</a>
      <ul>
        <li><a href="#simple-optimization-flow">Simple optimization flow</a></li>
        <li><a href="#the-role-of-the-surrogate-model">The Role of the Surrogate Model</a></li>
        <li><a href="#the-role-of-the-acquisition-function">The Role of the Acquisition Function</a></li>
        <li><a href="#maximizing-acquisition-function">Maximizing Acquisition Function</a></li>
      </ul>
    </li>
  </ul>
</nav>

 
    </aside>
    
  </main>

  
</body>

</html>












